# Nom du fichier : .github/workflows/deploy-addons.yml
# VERSION FINALE CORRIGÉE : Correction de la commande 'kubectl wait' pour compatibilité.

name: "APPS: Deploy or Destroy Kubernetes Add-ons"

on:
  push:
    branches: [main]
    paths: ['terraform/apps/**', '.github/workflows/deploy-addons.yml']
  pull_request:
    branches: [main]
    paths: ['terraform/apps/**', '.github/workflows/deploy-addons.yml']
  workflow_dispatch:
    inputs:
      action:
        description: 'Action: "apply" (déployer) ou "destroy" (détruire)'
        required: true
        default: 'apply'
        type: choice
        options: [apply, destroy]
      confirm_destroy:
        description: 'Si action=destroy, tapez "destroy-all-addons" pour confirmer.'
        required: false

jobs:
  # ===================================================================
  # JOB 1 : DÉPLOIEMENT (INCHANGÉ)
  # ===================================================================
  deploy-addons:
    name: "Terraform Apply for Add-ons"
    if: github.event.inputs.action == 'apply' || github.event_name == 'push'
    runs-on: ["self-hosted", "aws-private-runner"]
    defaults:
      run:
        shell: bash
        working-directory: ./terraform/apps
    steps:
      - name: Checkout source code 
        uses: actions/checkout@v4
      - name: Configure Kubeconfig for EKS
        run: |
          aws eks update-kubeconfig --region us-east-1 --name tws-eks-cluster
          kubectl get nodes -o wide
      - name: Terraform Init
        run: terraform init
      - name: Terraform Apply (for workflow_dispatch)
        if: github.event_name == 'workflow_dispatch' && github.event.inputs.action == 'apply'
        run: |
          terraform plan -no-color -out=plan-step1
          terraform apply -auto-approve -input=false plan-step1
          sleep 30
          terraform plan -no-color -out=plan-step2 -var="deploy_app_of_apps=true"
          terraform apply -auto-approve -input=false plan-step2
      - name: Validate Terraform Plan (on push)
        if: github.event_name == 'push'
        run: terraform plan -no-color

  # ===================================================================
  # JOB 2 : DESTRUCTION ORCHESTRÉE (LOGIQUE HYBRIDE CORRIGÉE)
  # ===================================================================
  destroy-addons:
    name: "Orchestrated Destroy for Add-ons"
    if: |
      github.event_name == 'workflow_dispatch' &&
      github.event.inputs.action == 'destroy' &&
      github.event.inputs.confirm_destroy == 'destroy-all-addons'
    
    runs-on: ["self-hosted", "aws-private-runner"]
    defaults:
      run:
        shell: bash
        working-directory: ./terraform/apps

    steps:
      - name: Checkout source code
        uses: actions/checkout@v4
      - name: Configure Kubeconfig for EKS
        run: |
          aws eks update-kubeconfig --region us-east-1 --name tws-eks-cluster
          kubectl get nodes

      # --- ÉTAPE 1 : FORÇAGE ET VÉRIFICATION DE LA SUPPRESSION DES NS 'QUIZ' ---
      - name: "Pre-Destroy: Force-Delete and Wait for Application Namespaces"
        if: github.event.inputs.action == 'destroy'
        run: |
          echo "--- [START] Force-deleting 'quiz' and 'quiz-staging' namespaces ---"
          for ns in quiz quiz-staging; do
            if kubectl get ns $ns > /dev/null 2>&1; then
              echo "Forcefully deleting namespace '$ns' by removing its finalizers..."
              kubectl get namespace $ns -o json | jq '.spec.finalizers = []' | kubectl replace --raw "/api/v1/namespaces/$ns/finalize" -f -
            else
              echo "Namespace '$ns' not found, skipping."
            fi
          done
          
          # --- CORRECTION DE LA VÉRIFICATION ---
          echo "Waiting up to 2 minutes for namespaces to be fully deleted..."
          for ns in quiz quiz-staging; do
            # On vérifie d'abord si le namespace existe avant de lancer le wait
            if kubectl get ns $ns > /dev/null 2>&1; then
              echo "Waiting for namespace '$ns' to be deleted..."
              kubectl wait --for=delete namespace/$ns --timeout=2m || echo "Timeout waiting for namespace '$ns' to delete."
            else
              echo "Namespace '$ns' was already deleted."
            fi
          done
          
          echo "--- [END] Application namespaces have been deleted. ---"
          echo "Current namespaces:"
          kubectl get ns

      # --- ÉTAPE 2 : DESTRUCTION DE L'INFRASTRUCTURE TERRAFORM ---
      - name: "Terraform Destroy (DANGEROUS)"
        if: github.event.inputs.action == 'destroy'
        run: |
          echo "--- [START] Running terraform destroy to delete remaining resources ---"
          terraform init
          terraform destroy -auto-approve -var="deploy_app_of_apps=true" || echo "Terraform destroy finished (may have errors on stuck resources, which is expected)."
          echo "--- [END] Terraform destroy command finished. ---"

      # --- ÉTAPE 3 : NETTOYAGE FINAL POUR ELASTICSEARCH ---
      - name: "Post-Destroy: Final Cleanup for Elasticsearch"
        if: github.event.inputs.action == 'destroy'
        run: |
          echo "--- [START] Cleaning up any remaining Elasticsearch PVCs ---"
          if kubectl get ns logging > /dev/null 2>&1; then
            echo "Deleting PVCs in namespace 'logging'..."
            # La commande delete a bien l'option --ignore-not-found
            kubectl delete pvc --all -n logging --ignore-not-found=true --timeout=5m
            
            echo "Waiting for pods in 'logging' namespace to terminate..."
            # On applique la même correction pour le wait sur les pods
            if kubectl get pod -n logging --no-headers | grep . > /dev/null 2>&1; then
              kubectl wait --for=delete pod --all -n logging --timeout=5m || echo "Timeout waiting for pods in 'logging' to delete."
            else
              echo "No pods found in 'logging' to wait for."
            fi
          else
            echo "Namespace 'logging' not found, skipping."
          fi
          echo "--- [END] Elasticsearch cleanup complete. ---"
